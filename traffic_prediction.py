# @Time    : 2020/8/25
# @Author  : LeronQ
# @github  : https://github.com/LeronQ

# Pytorch-åŸºäºGCN/GAT/Chebnetå›¾ç¥ç»ç½‘ç»œå®ç°çš„äº¤é€šæµé¢„æµ‹(é™„ä»£ç ): https://blog.csdn.net/yilulvxing/article/details/110306999

# traffic_prediction.py

import os
import time
import h5py
import torch
import numpy as np
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import DataLoader

# è¿™ä¸ªå°±æ˜¯ä¸Šä¸€å°èŠ‚å¤„ç†æ•°æ®è‡ªå·±å†™çš„çš„ç±»ï¼Œå°è£…åœ¨traffic_dataset.pyæ–‡ä»¶ä¸­
from traffic_dataset import LoadData
from utils import Evaluation  # ä¸‰ç§è¯„ä»·æŒ‡æ ‡ä»¥åŠå¯è§†åŒ–ç±»
from utils import visualize_result
from gcnnet import GCN
from chebnet import ChebNet
from gat import GATNet
from rich import print
from tqdm import tqdm

import warnings

warnings.filterwarnings('ignore')


def main():
    os.environ["CUDA_VISIBLE_DEVICES"] = "0"  # é…ç½®GPU,å› ä¸ºå¯èƒ½æœ‰å¤šä¸ªGPUï¼Œè¿™é‡Œç”¨äº†ç¬¬0å·GPU

    # ç¬¬ä¸€æ­¥ï¼šå‡†å¤‡æ•°æ®ï¼ˆä¸Šä¸€èŠ‚å·²ç»å‡†å¤‡å¥½äº†ï¼Œè¿™é‡Œåªæ˜¯è°ƒç”¨è€Œå·²ï¼Œé“¾æ¥åœ¨æœ€å¼€å¤´ï¼‰
    train_data = LoadData(data_path=["PeMS_04/PeMS04.csv", "PeMS_04/PeMS04.npz"], num_nodes=307, divide_days=[45, 14],
                          time_interval=5, history_length=6,
                          train_mode="train")

    # num_workersæ˜¯åŠ è½½æ•°æ®ï¼ˆbatchï¼‰çš„çº¿ç¨‹æ•°ç›®
    train_loader = DataLoader(
        train_data, batch_size=32, shuffle=True, num_workers=4)

    test_data = LoadData(data_path=["PeMS_04/PeMS04.csv", "PeMS_04/PeMS04.npz"], num_nodes=307, divide_days=[45, 14],
                         time_interval=5, history_length=6,
                         train_mode="test")

    test_loader = DataLoader(test_data, batch_size=32,
                             shuffle=False, num_workers=4)
    print("ğŸš€ğŸš€ğŸš€ [italic bold green]æ•°æ®åŠ è½½å®Œæˆ!!!")

    # SECTION: ç¬¬äºŒæ­¥ï¼šå®šä¹‰æ¨¡å‹ï¼ˆè¿™é‡Œå…¶å®åªæ˜¯åŠ è½½æ¨¡å‹ï¼Œå…³äºæ¨¡å‹çš„å®šä¹‰åœ¨ä¸‹é¢å•ç‹¬å†™äº†ï¼Œå…ˆå‡è®¾å·²ç»å†™å¥½ï¼‰
    my_net = GCN(in_c=6, hid_c=6, out_c=1)  # åŠ è½½GCNæ¨¡å‹
    # my_net = ChebNet(in_c=6, hid_c=6, out_c=1, K=2)   # åŠ è½½ChebNetæ¨¡å‹
    # my_net = GATNet(in_c=6 * 1, hid_c=6, out_c=1, n_heads=2)  # åŠ è½½GATæ¨¡å‹
    print(my_net)

    device = torch.device(
        "cuda" if torch.cuda.is_available() else "cpu")  # å®šä¹‰è®¾å¤‡

    my_net = my_net.to(device)  # æ¨¡å‹é€å…¥è®¾å¤‡

    # ç¬¬ä¸‰æ­¥ï¼šå®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
    criterion = nn.MSELoss()  # å‡æ–¹æŸå¤±å‡½æ•°

    # æ²¡å†™å­¦ä¹ ç‡ï¼Œè¡¨ç¤ºä½¿ç”¨çš„æ˜¯é»˜è®¤çš„ï¼Œä¹Ÿå°±æ˜¯lr=1e-3
    optimizer = optim.Adam(params=my_net.parameters())

    # ç¬¬å››æ­¥ï¼šè®­ç»ƒ+æµ‹è¯•
    # Train model
    Epoch = 20  # è®­ç»ƒçš„æ¬¡æ•°

    my_net.train()  # æ‰“å¼€è®­ç»ƒæ¨¡å¼
    for epoch in tqdm(range(Epoch), colour="green", desc="Train"):
        epoch_loss = 0.0
        count = 0
        start_time = time.time()
        # ["graph": [B, N, N] , "flow_x": [B, N, H, D], "flow_y": [B, N, 1, D]],ä¸€æ¬¡æŠŠä¸€ä¸ªbatchçš„è®­ç»ƒæ•°æ®å–å‡ºæ¥
        for data in train_loader:
            my_net.zero_grad()  # æ¢¯åº¦æ¸…é›¶
            count += 1
            # [B, N, 1, D],ç”±äºæ ‡ç­¾flow_yåœ¨cpuä¸­ï¼Œæ‰€ä»¥æœ€åçš„é¢„æµ‹å€¼è¦æ”¾å›åˆ°cpuä¸­
            predict_value = my_net(data, device).to(torch.device("cpu"))

            # è®¡ç®—æŸå¤±ï¼Œåˆ‡è®°è¿™ä¸ªlossä¸æ˜¯æ ‡é‡
            loss = criterion(predict_value, data["flow_y"])

            epoch_loss += loss.item()  # è¿™é‡Œæ˜¯æŠŠä¸€ä¸ªepochçš„æŸå¤±éƒ½åŠ èµ·æ¥ï¼Œæœ€åå†é™¤è®­ç»ƒæ•°æ®é•¿åº¦ï¼Œç”¨å¹³å‡lossæ¥è¡¨ç¤º

            loss.backward()  # åå‘ä¼ æ’­

            optimizer.step()  # æ›´æ–°å‚æ•°
        end_time = time.time()

        print("Epoch: {:04d}, Loss: {:02.4f}, Time: {:02.2f} mins".format(epoch, 1000 * epoch_loss / len(train_data),
                                                                          (end_time - start_time) / 60))

    # Test Model
    # å¯¹äºæµ‹è¯•:
    # ç¬¬ä¸€ã€é™¤äº†è®¡ç®—lossä¹‹å¤–ï¼Œè¿˜éœ€è¦å¯è§†åŒ–ä¸€ä¸‹é¢„æµ‹çš„ç»“æœï¼ˆå®šæ€§åˆ†æï¼‰
    # ç¬¬äºŒã€å¯¹äºé¢„æµ‹çš„ç»“æœè¿™é‡Œæˆ‘ä½¿ç”¨äº† MAE, MAPE, and RMSE è¿™ä¸‰ç§è¯„ä»·æ ‡å‡†æ¥è¯„ä¼°ï¼ˆå®šé‡åˆ†æï¼‰
    my_net.eval()  # æ‰“å¼€æµ‹è¯•æ¨¡å¼
    with torch.no_grad():  # å…³é—­æ¢¯åº¦
        MAE, MAPE, RMSE = [], [], []  # å®šä¹‰ä¸‰ç§æŒ‡æ ‡çš„åˆ—è¡¨
        Target = np.zeros([307, 1, 1])  # [N, T, D],T=1 ï¼ƒ ç›®æ ‡æ•°æ®çš„ç»´åº¦ï¼Œç”¨ï¼å¡«å……
        Predict = np.zeros_like(Target)  # [N, T, D],T=1 # é¢„æµ‹æ•°æ®çš„ç»´åº¦

        total_loss = 0.0
        for data in test_loader:  # ä¸€æ¬¡æŠŠä¸€ä¸ªbatchçš„æµ‹è¯•æ•°æ®å–å‡ºæ¥

            # ä¸‹é¢å¾—åˆ°çš„é¢„æµ‹ç»“æœå®é™…ä¸Šæ˜¯å½’ä¸€åŒ–çš„ç»“æœï¼Œæœ‰ä¸€ä¸ªé—®é¢˜æ˜¯æˆ‘ä»¬è¿™é‡Œä½¿ç”¨çš„ä¸‰ç§è¯„ä»·æ ‡å‡†ä»¥åŠå¯è§†åŒ–ç»“æœè¦ç”¨çš„æ˜¯é€†å½’ä¸€åŒ–çš„æ•°æ®
            # [B, N, 1, D]ï¼ŒBæ˜¯batch_size, Næ˜¯èŠ‚ç‚¹æ•°é‡,1æ˜¯æ—¶é—´T=1, Dæ˜¯èŠ‚ç‚¹çš„æµé‡ç‰¹å¾
            predict_value = my_net(data, device).to(torch.device("cpu"))

            loss = criterion(predict_value, data["flow_y"])  # ä½¿ç”¨MSEè®¡ç®—loss

            total_loss += loss.item()  # æ‰€æœ‰çš„batchçš„lossç´¯åŠ 
            # ä¸‹é¢å®é™…ä¸Šæ˜¯æŠŠé¢„æµ‹å€¼å’Œç›®æ ‡å€¼çš„batchæ”¾åˆ°ç¬¬äºŒç»´çš„æ—¶é—´ç»´åº¦ï¼Œè¿™æ˜¯å› ä¸ºåœ¨æµ‹è¯•æ•°æ®çš„æ—¶å€™å¯¹æ ·æœ¬æ²¡æœ‰shuffleï¼Œ
            # æ‰€ä»¥æ¯ä¸€ä¸ªbatchå–å‡ºæ¥çš„æ•°æ®å°±æ˜¯æŒ‰æ—¶é—´é¡ºåºæ¥çš„ï¼Œå› æ­¤æ”¾åˆ°ç¬¬äºŒç»´æ¥è¡¨ç¤ºæ—¶é—´æ˜¯åˆç†çš„.
            predict_value = predict_value.transpose(0, 2).squeeze(
                0)  # [1, N, B(T), D] -> [N, B(T), D] -> [N, T, D]
            target_value = data["flow_y"].transpose(0, 2).squeeze(
                0)  # [1, N, B(T), D] -> [N, B(T), D] -> [N, T, D]

            performance, data_to_save = compute_performance(
                predict_value, target_value, test_loader)  # è®¡ç®—æ¨¡å‹çš„æ€§èƒ½ï¼Œè¿”å›è¯„ä»·ç»“æœå’Œæ¢å¤å¥½çš„æ•°æ®

            # ä¸‹é¢è¿™ä¸ªæ˜¯æ¯ä¸€ä¸ªbatchå–å‡ºçš„æ•°æ®ï¼ŒæŒ‰batchè¿™ä¸ªç»´åº¦è¿›è¡Œä¸²è”ï¼Œæœ€åå°±å¾—åˆ°äº†æ•´ä¸ªæ—¶é—´çš„æ•°æ®ï¼Œä¹Ÿå°±æ˜¯
            # [N, T, D] = [N, T1+T2+..., D]
            Predict = np.concatenate([Predict, data_to_save[0]], axis=1)
            Target = np.concatenate([Target, data_to_save[1]], axis=1)

            MAE.append(performance[0])
            MAPE.append(performance[1])
            RMSE.append(performance[2])

            print("Test Loss: {:02.4f}".format(1000 * total_loss / len(test_data)))

    # ä¸‰ç§æŒ‡æ ‡å–å¹³å‡
    print("Performance:  MAE {:2.2f}    {:2.2f}%    {:2.2f}".format(np.mean(MAE), np.mean(MAPE * 100), np.mean(RMSE)))

    # å°†ç¬¬0è¡Œçš„0åˆ é™¤ï¼Œå› ä¸ºå¼€å§‹å®šä¹‰çš„æ—¶å€™ç”¨0å¡«å……ï¼Œä½†æ˜¯æ—¶é—´æ˜¯ä»1å¼€å§‹çš„
    Predict = np.delete(Predict, 0, axis=1)
    Target = np.delete(Target, 0, axis=1)

    result_file = "GAT_result.h5"
    file_obj = h5py.File(result_file, "w")  # å°†é¢„æµ‹å€¼å’Œç›®æ ‡å€¼ä¿å­˜åˆ°æ–‡ä»¶ä¸­ï¼Œå› ä¸ºè¦å¤šæ¬¡å¯è§†åŒ–çœ‹çœ‹ç»“æœ

    file_obj["predict"] = Predict  # [N, T, D]
    file_obj["target"] = Target  # [N, T, D]


def compute_performance(prediction, target, data):  # è®¡ç®—æ¨¡å‹æ€§èƒ½
    # ä¸‹é¢çš„tryå’Œexceptå®é™…ä¸Šåœ¨åšè¿™æ ·ä¸€ä»¶äº‹ï¼šå½“è®­ç»ƒ+æµ‹è¯•æ¨¡å‹çš„æ—¶å€™ï¼Œæ•°æ®è‚¯å®šæ˜¯ç»è¿‡dataloaderçš„ï¼Œæ‰€ä»¥ç›´æ¥èµ‹å€¼å°±å¯ä»¥äº†
    # ä½†æ˜¯å¦‚æœå°†è®­ç»ƒå¥½çš„æ¨¡å‹ä¿å­˜ä¸‹æ¥ï¼Œç„¶åæµ‹è¯•ï¼Œé‚£ä¹ˆæ•°æ®å°±æ²¡æœ‰ç»è¿‡dataloaderï¼Œæ˜¯dataloaderå‹çš„ï¼Œéœ€è¦è½¬æ¢æˆdatasetå‹ã€‚
    try:
        dataset = data.dataset  # æ•°æ®ä¸ºdataloaderå‹ï¼Œé€šè¿‡å®ƒä¸‹é¢çš„å±æ€§.datasetç±»å˜æˆdatasetå‹æ•°æ®
    except:
        dataset = data  # æ•°æ®ä¸ºdatasetå‹ï¼Œç›´æ¥èµ‹å€¼

    # ä¸‹é¢å°±æ˜¯å¯¹é¢„æµ‹å’Œç›®æ ‡æ•°æ®è¿›è¡Œé€†å½’ä¸€åŒ–ï¼Œrecover_data()å‡½æ•°åœ¨ä¸Šä¸€å°èŠ‚çš„æ•°æ®å¤„ç†ä¸­
    #  flow_normä¸ºå½’ä¸€åŒ–çš„åŸºï¼Œflow_norm[0]ä¸ºæœ€å¤§å€¼ï¼Œflow_norm[1]ä¸ºæœ€å°å€¼
    # prediction.numpy()å’Œtarget.numpy()æ˜¯éœ€è¦é€†å½’ä¸€åŒ–çš„æ•°æ®ï¼Œè½¬æ¢æˆnumpyå‹æ˜¯å› ä¸º recover_data()å‡½æ•°ä¸­çš„æ•°æ®éƒ½æ˜¯numpyå‹ï¼Œä¿æŒä¸€è‡´
    prediction = LoadData.recover_data(
        dataset.flow_norm[0], dataset.flow_norm[1], prediction.numpy())
    target = LoadData.recover_data(
        dataset.flow_norm[0], dataset.flow_norm[1], target.numpy())

    # å¯¹ä¸‰ç§è¯„ä»·æŒ‡æ ‡å†™äº†ä¸€ä¸ªç±»ï¼Œè¿™ä¸ªç±»å°è£…åœ¨å¦ä¸€ä¸ªæ–‡ä»¶ä¸­ï¼Œåœ¨åé¢
    mae, mape, rmse = Evaluation.total(
        target.reshape(-1), prediction.reshape(-1))  # å˜æˆå¸¸å‘é‡æ‰èƒ½è®¡ç®—è¿™ä¸‰ç§æŒ‡æ ‡

    performance = [mae, mape, rmse]
    recovered_data = [prediction, target]

    return performance, recovered_data  # è¿”å›è¯„ä»·ç»“æœï¼Œä»¥åŠæ¢å¤å¥½çš„æ•°æ®ï¼ˆä¸ºå¯è§†åŒ–å‡†å¤‡çš„ï¼‰


if __name__ == '__main__':
    main()
    # å¯è§†åŒ–ï¼Œåœ¨ä¸‹é¢çš„ Evaluation()ç±»ä¸­ï¼Œè¿™é‡Œæ˜¯å¯¹åº”çš„GATç®—æ³•è¿è¡Œçš„ç»“æœï¼Œè¿›è¡Œå¯è§†åŒ–
    # å¦‚æœè¦å¯¹GCNæˆ–è€…chebnetè¿›è¡Œå¯è§†åŒ–ï¼Œåªéœ€è¦åœ¨ç¬¬45è¡Œï¼Œæ³¨é‡Šä¿®æ”¹ä¸‹å¯¹åº”çš„ç®—æ³•å³å¯
    visualize_result(h5_file="GAT_result.h5",
                     nodes_id=120, time_se=[0, 24 * 12 * 2],  # æ˜¯èŠ‚ç‚¹çš„æ—¶é—´èŒƒå›´
                     visualize_file="gat_node_120")
